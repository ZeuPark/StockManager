"""
Daily Financial News Analysis
ì–´ì œ ê¸ˆìœµ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ê³  ê°ì • ë¶„ì„ìœ¼ë¡œ ì˜ë¯¸ ìˆëŠ” ì£¼ì‹ë“¤ì„ ì°¾ëŠ” í”„ë¡œê·¸ë¨
"""

import sys
import os
from datetime import datetime, timedelta
import pandas as pd
import re
from collections import Counter
import logging

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from simple_naver_crawler import SimpleNaverCrawler

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class DailyNewsAnalyzer:
    """ì¼ì¼ ë‰´ìŠ¤ ë¶„ì„ê¸°"""
    
    def __init__(self):
        self.crawler = SimpleNaverCrawler()
        
        # ì£¼ì‹ ê´€ë ¨ í‚¤ì›Œë“œ (ì¢…ëª©ëª…, ê¸°ì—…ëª…)
        self.stock_keywords = [
            'ì‚¼ì„±ì „ì', 'SKí•˜ì´ë‹‰ìŠ¤', 'LGì—ë„ˆì§€ì†”ë£¨ì…˜', 'ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤', 'NAVER', 'ì¹´ì¹´ì˜¤',
            'í˜„ëŒ€ì°¨', 'ê¸°ì•„', 'LGí™”í•™', 'POSCOí™€ë”©ìŠ¤', 'ì‚¼ì„±SDI', 'LGì „ì', 'í˜„ëŒ€ëª¨ë¹„ìŠ¤',
            'KBê¸ˆìœµ', 'ì‹ í•œì§€ì£¼', 'í•˜ë‚˜ê¸ˆìœµì§€ì£¼', 'ìš°ë¦¬ê¸ˆìœµì§€ì£¼', 'NHíˆ¬ìì¦ê¶Œ', 'ë¯¸ë˜ì—ì…‹ì¦ê¶Œ',
            'ì‚¼ì„±ìƒëª…', 'êµë³´ìƒëª…', 'í•œí™”ìƒëª…', 'DBì†í•´ë³´í—˜', 'ë©”ë¦¬ì¸ í™”ì¬',
            'SKì´ë…¸ë² ì´ì…˜', 'SKí…”ë ˆì½¤', 'KT', 'LGìœ í”ŒëŸ¬ìŠ¤', 'SKë°”ì´ì˜¤íŒœ',
            'CJëŒ€í•œí†µìš´', 'í•œêµ­ì „ë ¥', 'GSê±´ì„¤', 'ë¡¯ë°ê±´ì„¤', 'í¬ìŠ¤ì½”í“¨ì²˜ì— ',
            'LGë””ìŠ¤í”Œë ˆì´', 'ì‚¼ì„±ì „ê¸°', 'ì‚¼ì„±í™”ì¬', 'í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤', 'ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹°',
            'LGìœ í”ŒëŸ¬ìŠ¤', 'SKìŠ¤í€˜ì–´', 'LGí™”í•™', 'ì‚¼ì„±ë¬¼ì‚°', 'ë¡¯ë°ì •ë³´í†µì‹ ',
            'í˜„ëŒ€ì¤‘ê³µì—…', 'ë‘ì‚°ì¸í”„ë¼ì½”ì–´', 'í•œí™”ì‹œìŠ¤í…œ', 'LIGë„¥ìŠ¤ì›', 'í•œí™”ì—ì–´ë¡œìŠ¤í˜ì´ìŠ¤',
            'CJì œì¼ì œë‹¹', 'ë†ì‹¬', 'ì˜¤ë¦¬ì˜¨', 'ë¡¯ë°ì¹ ì„±', 'ë™ì„œ', 'ë¡¯ë°ì œê³¼',
            'ì‹ ì„¸ê³„', 'ì´ë§ˆíŠ¸', 'ë¡¯ë°ì‡¼í•‘', 'CJëŒ€í•œí†µìš´', 'í•œì§„', 'ëŒ€í•œí•­ê³µ',
            'ì•„ì‹œì•„ë‚˜í•­ê³µ', 'ì½”ì›¨ì´', 'LGìƒí™œê±´ê°•', 'ì•„ëª¨ë ˆí¼ì‹œí”½', 'LGí™”í•™',
            'SKë°”ì´ì˜¤íŒœ', 'ì…€íŠ¸ë¦¬ì˜¨', 'í•œë¯¸ì•½í’ˆ', 'ìœ í•œì–‘í–‰', 'ë™êµ­ì œì•½',
            'ëŒ€ìš°ê±´ì„¤', 'GSê±´ì„¤', 'ë¡¯ë°ê±´ì„¤', 'í¬ìŠ¤ì½”ê±´ì„¤', 'í˜„ëŒ€ê±´ì„¤',
            'í•œêµ­ì „ë ¥', 'í•œêµ­ê°€ìŠ¤ê³µì‚¬', 'GSì¹¼í…ìŠ¤', 'S-OIL', 'SKì´ë…¸ë² ì´ì…˜'
        ]
        
        # ê°ì • ë¶„ì„ í‚¤ì›Œë“œ
        self.positive_keywords = [
            'ìƒìŠ¹', 'ê¸‰ë“±', 'í˜¸ì¬', 'ì‹¤ì ê°œì„ ', 'ì„±ì¥', 'í™•ëŒ€', 'ì§„ì¶œ', 'ìˆ˜ì£¼', 'ê³„ì•½',
            'ìŠ¹ì¸', 'í—ˆê°€', 'ê°œë°œì„±ê³µ', 'íŠ¹í—ˆ', 'ì‹ ì œí’ˆ', 'í•´ì™¸ì§„ì¶œ', 'ìˆ˜ìµì¦ê°€',
            'ë§¤ìˆ˜', 'íˆ¬ì', 'ê¸°ëŒ€', 'ì „ë§', 'ê¸ì •', 'ì¢‹ìŒ', 'ê°•ì„¸', 'ëŒíŒŒ',
            'ìƒí–¥', 'ì¦ê°€', 'ê°œì„ ', 'íšŒë³µ', 'ë°˜ë“±', 'ìƒìŠ¹ì„¸', 'í˜¸ì¡°', 'ì„±ì¥ì„¸'
        ]
        
        self.negative_keywords = [
            'í•˜ë½', 'ê¸‰ë½', 'ì•…ì¬', 'ì‹¤ì ì•…í™”', 'ì†ì‹¤', 'ì¶•ì†Œ', 'ì² ìˆ˜', 'ê³„ì•½í•´ì§€',
            'ë°˜ëŒ€', 'ê±°ë¶€', 'ê°œë°œì‹¤íŒ¨', 'íŠ¹í—ˆë¬´íš¨', 'ë¦¬ì½œ', 'í•´ì™¸ì² ìˆ˜', 'ìˆ˜ìµê°ì†Œ',
            'ë§¤ë„', 'ë§¤ë„ì„¸', 'ë¶€ì •', 'ë‚˜ì¨', 'ì•½ì„¸', 'ìœ„í—˜', 'í•˜í–¥', 'ê°ì†Œ',
            'ì•…í™”', 'ì†ì‹¤', 'í­ë½', 'í•˜ë½ì„¸', 'ì•½ì„¸', 'ë¶€ì§„', 'ì‹¤íŒ¨', 'ì‹¤ì ë¶€ì§„'
        ]
    
    def collect_yesterday_news(self, date_str: str = None) -> list:
        """ì–´ì œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        if date_str is None:
            yesterday = datetime.now() - timedelta(days=1)
            date_str = yesterday.strftime('%Y-%m-%d')
        
        logger.info(f"{date_str} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘...")
        
        all_news = []
        
        # ê²½ì œ, ì£¼ì‹, ê¸°ì—… ë‰´ìŠ¤ ìˆ˜ì§‘
        categories = ['economy', 'stock', 'company']
        for category in categories:
            try:
                news_list = self.crawler.get_news_by_date(date_str, category)
                all_news.extend(news_list)
                logger.info(f"{category} ë‰´ìŠ¤ {len(news_list)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")
            except Exception as e:
                logger.error(f"{category} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        
        logger.info(f"ì´ {len(all_news)}ê°œ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ")
        return all_news
    
    def extract_stock_mentions(self, text: str) -> list:
        """í…ìŠ¤íŠ¸ì—ì„œ ì£¼ì‹ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        mentions = []
        for keyword in self.stock_keywords:
            if keyword in text:
                mentions.append(keyword)
        return mentions
    
    def analyze_sentiment(self, text: str) -> dict:
        """ê°ì • ë¶„ì„"""
        if not text or pd.isna(text):
            return {'positive': 0.0, 'negative': 0.0, 'neutral': 1.0}
        
        text = str(text).lower()
        
        # í‚¤ì›Œë“œ ì¹´ìš´íŠ¸
        positive_count = sum(1 for keyword in self.positive_keywords if keyword in text)
        negative_count = sum(1 for keyword in self.negative_keywords if keyword in text)
        
        total_keywords = positive_count + negative_count
        
        if total_keywords == 0:
            return {'positive': 0.0, 'negative': 0.0, 'neutral': 1.0}
        
        positive_score = positive_count / total_keywords
        negative_score = negative_count / total_keywords
        neutral_score = 1.0 - positive_score - negative_score
        
        return {
            'positive': positive_score,
            'negative': negative_score,
            'neutral': neutral_score
        }
    
    def analyze_news_with_stocks(self, news_list: list) -> pd.DataFrame:
        """ë‰´ìŠ¤ì—ì„œ ì£¼ì‹ ì–¸ê¸‰ê³¼ ê°ì • ë¶„ì„"""
        results = []
        
        for news in news_list:
            # ì œëª©ê³¼ ë³¸ë¬¸ ê²°í•©
            full_text = f"{news.get('title', '')} {news.get('content', '')}"
            
            # ì£¼ì‹ í‚¤ì›Œë“œ ì¶”ì¶œ
            stock_mentions = self.extract_stock_mentions(full_text)
            
            if stock_mentions:  # ì£¼ì‹ì´ ì–¸ê¸‰ëœ ë‰´ìŠ¤ë§Œ ë¶„ì„
                # ê°ì • ë¶„ì„
                sentiment = self.analyze_sentiment(full_text)
                
                for stock in stock_mentions:
                    results.append({
                        'date': news.get('date'),
                        'stock': stock,
                        'title': news.get('title', ''),
                        'source': news.get('source', ''),
                        'url': news.get('url', ''),
                        'positive_score': sentiment['positive'],
                        'negative_score': sentiment['negative'],
                        'neutral_score': sentiment['neutral'],
                        'sentiment_direction': 'positive' if sentiment['positive'] > sentiment['negative'] else 'negative' if sentiment['negative'] > sentiment['positive'] else 'neutral'
                    })
        
        return pd.DataFrame(results)
    
    def get_significant_stocks(self, df: pd.DataFrame, min_mentions: int = 2) -> pd.DataFrame:
        """ì˜ë¯¸ ìˆëŠ” ì£¼ì‹ë“¤ ì¶”ì¶œ"""
        if len(df) == 0:
            return pd.DataFrame()
        
        # ì£¼ì‹ë³„ í†µê³„
        stock_stats = df.groupby('stock').agg({
            'positive_score': ['mean', 'sum'],
            'negative_score': ['mean', 'sum'],
            'neutral_score': 'mean',
            'sentiment_direction': lambda x: x.value_counts().index[0] if len(x) > 0 else 'neutral'
        }).round(3)
        
        # ì»¬ëŸ¼ëª… ì •ë¦¬
        stock_stats.columns = ['avg_positive', 'total_positive', 'avg_negative', 'total_negative', 'avg_neutral', 'dominant_sentiment']
        
        # ì–¸ê¸‰ íšŸìˆ˜ ì¶”ê°€
        mention_counts = df['stock'].value_counts()
        stock_stats['mention_count'] = mention_counts
        
        # ìµœì†Œ ì–¸ê¸‰ íšŸìˆ˜ í•„í„°ë§
        significant_stocks = stock_stats[stock_stats['mention_count'] >= min_mentions]
        
        # ê°ì • ì ìˆ˜ ì°¨ì´ ê³„ì‚°
        significant_stocks['sentiment_diff'] = significant_stocks['avg_positive'] - significant_stocks['avg_negative']
        
        # ìˆœìœ„ ë§¤ê¸°ê¸° (ê¸ì • ì ìˆ˜ ë†’ì€ ìˆœ)
        significant_stocks = significant_stocks.sort_values('avg_positive', ascending=False)
        
        return significant_stocks
    
    def print_analysis_results(self, df: pd.DataFrame, stock_stats: pd.DataFrame):
        """ë¶„ì„ ê²°ê³¼ ì¶œë ¥"""
        print(f"\n=== {df['date'].iloc[0] if len(df) > 0 else 'N/A'} ê¸ˆìœµ ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ===")
        print(f"ì´ ë‰´ìŠ¤ ìˆ˜: {len(df)}ê°œ")
        print(f"ì–¸ê¸‰ëœ ì£¼ì‹ ìˆ˜: {len(stock_stats)}ê°œ")
        
        if len(stock_stats) == 0:
            print("ë¶„ì„í•  ì£¼ì‹ì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"\n=== ì˜ë¯¸ ìˆëŠ” ì£¼ì‹ TOP 10 ===")
        print("ìˆœìœ„ | ì¢…ëª©ëª… | ì–¸ê¸‰íšŸìˆ˜ | í‰ê· ê¸ì •ì ìˆ˜ | í‰ê· ë¶€ì •ì ìˆ˜ | ê°ì •ë°©í–¥ | ê°ì •ì°¨ì´")
        print("-" * 80)
        
        for i, (stock, row) in enumerate(stock_stats.head(10).iterrows(), 1):
            sentiment_emoji = "ğŸ“ˆ" if row['dominant_sentiment'] == 'positive' else "ğŸ“‰" if row['dominant_sentiment'] == 'negative' else "â¡ï¸"
            print(f"{i:2d} | {stock:12s} | {row['mention_count']:8d} | {row['avg_positive']:12.3f} | {row['avg_negative']:12.3f} | {sentiment_emoji} {row['dominant_sentiment']:8s} | {row['sentiment_diff']:8.3f}")
        
        # ê¸ì •ì ì¸ ì£¼ì‹ë“¤
        positive_stocks = stock_stats[stock_stats['dominant_sentiment'] == 'positive'].head(5)
        if len(positive_stocks) > 0:
            print(f"\n=== ğŸ“ˆ ê¸ì •ì ì¸ ì£¼ì‹ TOP 5 ===")
            for i, (stock, row) in enumerate(positive_stocks.iterrows(), 1):
                print(f"{i}. {stock} (ì–¸ê¸‰: {row['mention_count']}íšŒ, ê¸ì •ì ìˆ˜: {row['avg_positive']:.3f})")
        
        # ë¶€ì •ì ì¸ ì£¼ì‹ë“¤
        negative_stocks = stock_stats[stock_stats['dominant_sentiment'] == 'negative'].head(5)
        if len(negative_stocks) > 0:
            print(f"\n=== ğŸ“‰ ë¶€ì •ì ì¸ ì£¼ì‹ TOP 5 ===")
            for i, (stock, row) in enumerate(negative_stocks.iterrows(), 1):
                print(f"{i}. {stock} (ì–¸ê¸‰: {row['mention_count']}íšŒ, ë¶€ì •ì ìˆ˜: {row['avg_negative']:.3f})")
    
    def save_results(self, df: pd.DataFrame, stock_stats: pd.DataFrame, date_str: str):
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ìƒì„¸ ë°ì´í„° ì €ì¥
        detail_filename = f"daily_analysis_{date_str}_{timestamp}.csv"
        df.to_csv(detail_filename, index=False, encoding='utf-8-sig')
        
        # ì£¼ì‹ í†µê³„ ì €ì¥
        stats_filename = f"stock_stats_{date_str}_{timestamp}.csv"
        stock_stats.to_csv(stats_filename, encoding='utf-8-sig')
        
        print(f"\n=== ê²°ê³¼ ì €ì¥ ì™„ë£Œ ===")
        print(f"ìƒì„¸ ë°ì´í„°: {detail_filename}")
        print(f"ì£¼ì‹ í†µê³„: {stats_filename}")

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    analyzer = DailyNewsAnalyzer()
    
    # ì–´ì œ ë‚ ì§œ (2025-07-16)
    target_date = "2025-07-16"
    
    print(f"=== {target_date} ê¸ˆìœµ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘ ===")
    
    try:
        # 1. ë‰´ìŠ¤ ìˆ˜ì§‘
        print("1. ë‰´ìŠ¤ ìˆ˜ì§‘ ì¤‘...")
        news_list = analyzer.collect_yesterday_news(target_date)
        
        if not news_list:
            print("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 2. ì£¼ì‹ ì–¸ê¸‰ ë° ê°ì • ë¶„ì„
        print("2. ì£¼ì‹ ì–¸ê¸‰ ë° ê°ì • ë¶„ì„ ì¤‘...")
        analysis_df = analyzer.analyze_news_with_stocks(news_list)
        
        if len(analysis_df) == 0:
            print("ì£¼ì‹ì´ ì–¸ê¸‰ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # 3. ì˜ë¯¸ ìˆëŠ” ì£¼ì‹ ì¶”ì¶œ
        print("3. ì˜ë¯¸ ìˆëŠ” ì£¼ì‹ ì¶”ì¶œ ì¤‘...")
        stock_stats = analyzer.get_significant_stocks(analysis_df, min_mentions=2)
        
        # 4. ê²°ê³¼ ì¶œë ¥
        analyzer.print_analysis_results(analysis_df, stock_stats)
        
        # 5. ê²°ê³¼ ì €ì¥
        analyzer.save_results(analysis_df, stock_stats, target_date)
        
    except Exception as e:
        print(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
        logger.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    main() 