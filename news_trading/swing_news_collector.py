"""
ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°
3-7ì¼ ë³´ìœ  ê¸°ê°„ì— ìµœì í™”ëœ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘
"""

import pandas as pd
from datetime import datetime, timedelta
import logging
from typing import List, Dict, Any
from .naver_crawler import NaverNewsCrawler
from .config import SWING_TRADING_NEWS_CONFIG, SENTIMENT_CONFIG

logger = logging.getLogger(__name__)

class SwingNewsCollector:
    """ìŠ¤ìœ™ íŠ¸ë ˆì´ë”©ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ê¸°"""
    
    def __init__(self):
        self.crawler = NaverNewsCrawler(headless=True)
        self.config = SWING_TRADING_NEWS_CONFIG
        
    def collect_daily_news(self, days: int = 5) -> pd.DataFrame:
        """ì¼ê°„ ë§¤ë§¤ íŒë‹¨ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ (ì „ì¼ + ê¸ˆì¼ ìƒˆë²½)"""
        logger.info(f"ì¼ê°„ ë§¤ë§¤ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: ìµœê·¼ {days}ì¼")
        
        all_news = []
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ìˆ˜ì§‘
        categories = ["economy", "stock", "company"]
        
        for category in categories:
            try:
                if category == "economy":
                    news = self.crawler.crawl_economy_news(max_pages=3)
                elif category == "stock":
                    news = self.crawler.crawl_stock_news(max_pages=3)
                elif category == "company":
                    news = self.crawler.crawl_company_news(max_pages=3)
                
                all_news.extend(news)
                logger.info(f"{category} ë‰´ìŠ¤: {len(news)}ê°œ ìˆ˜ì§‘")
                
            except Exception as e:
                logger.error(f"{category} ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        # DataFrameìœ¼ë¡œ ë³€í™˜
        df = pd.DataFrame(all_news)
        
        if not df.empty:
            # íƒ€ì„ìŠ¤íƒ¬í”„ íŒŒì‹±
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            df['date'] = df['timestamp'].dt.date
            
            # ìµœê·¼ Nì¼ í•„í„°ë§
            cutoff_date = datetime.now().date() - timedelta(days=days)
            df = df[df['date'] >= cutoff_date]
            
            # ì¤‘ë³µ ì œê±°
            df = df.drop_duplicates(subset=['url'])
            
            logger.info(f"ì¼ê°„ ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {len(df)}ê°œ")
            
            # CSV ì €ì¥
            filename = f"swing_daily_news_{datetime.now().strftime('%Y%m%d')}.csv"
            df.to_csv(filename, index=False, encoding="utf-8-sig")
            logger.info(f"ì €ì¥ ì™„ë£Œ: {filename}")
        
        return df
    
    def collect_trigger_news(self, days: int = 7) -> pd.DataFrame:
        """íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸ íƒìƒ‰ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ (3-7ì¼ì¹˜)"""
        logger.info(f"íŠ¸ë¦¬ê±° ì´ë²¤íŠ¸ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: ìµœê·¼ {days}ì¼")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§
        trigger_keywords = self.config["real_time"]["keywords"]
        
        df = self.collect_daily_news(days)
        
        if not df.empty:
            # í‚¤ì›Œë“œ í•„í„°ë§
            filtered_news = []
            for _, row in df.iterrows():
                title_content = f"{row['title']} {row['content']}"
                
                # í‚¤ì›Œë“œ ë§¤ì¹­
                matched_keywords = []
                for keyword in trigger_keywords:
                    if keyword in title_content:
                        matched_keywords.append(keyword)
                
                if matched_keywords:
                    row_dict = row.to_dict()
                    row_dict['matched_keywords'] = ', '.join(matched_keywords)
                    row_dict['keyword_count'] = len(matched_keywords)
                    filtered_news.append(row_dict)
            
            if filtered_news:
                trigger_df = pd.DataFrame(filtered_news)
                trigger_df = trigger_df.sort_values('keyword_count', ascending=False)
                
                # CSV ì €ì¥
                filename = f"swing_trigger_news_{datetime.now().strftime('%Y%m%d')}.csv"
                trigger_df.to_csv(filename, index=False, encoding="utf-8-sig")
                logger.info(f"íŠ¸ë¦¬ê±° ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ: {filename} ({len(trigger_df)}ê°œ)")
                
                return trigger_df
        
        return pd.DataFrame()
    
    def collect_trend_news(self, weeks: int = 2) -> pd.DataFrame:
        """ì „ì²´ íŠ¸ë Œë“œ ë¶„ì„ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ (2-4ì£¼)"""
        logger.info(f"íŠ¸ë Œë“œ ë¶„ì„ìš© ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹œì‘: ìµœê·¼ {weeks}ì£¼")
        
        days = weeks * 7
        df = self.collect_daily_news(days)
        
        if not df.empty:
            # ì£¼ì°¨ë³„ ê·¸ë£¹í•‘
            df['week'] = df['timestamp'].dt.isocalendar().week
            df['year'] = df['timestamp'].dt.year
            
            # ì¹´í…Œê³ ë¦¬ë³„ í†µê³„
            category_stats = df.groupby('category').agg({
                'title': 'count',
                'timestamp': ['min', 'max']
            }).round(2)
            
            logger.info(f"ì¹´í…Œê³ ë¦¬ë³„ í†µê³„:\n{category_stats}")
            
            # CSV ì €ì¥
            filename = f"swing_trend_news_{datetime.now().strftime('%Y%m%d')}.csv"
            df.to_csv(filename, index=False, encoding="utf-8-sig")
            logger.info(f"íŠ¸ë Œë“œ ë‰´ìŠ¤ ì €ì¥ ì™„ë£Œ: {filename}")
        
        return df
    
    def analyze_news_patterns(self, months: int = 1) -> Dict[str, Any]:
        """ë‰´ìŠ¤-ì£¼ê°€ ë°˜ì‘ íŒ¨í„´ ë¶„ì„ (1-3ê°œì›”)"""
        logger.info(f"ë‰´ìŠ¤ íŒ¨í„´ ë¶„ì„ ì‹œì‘: ìµœê·¼ {months}ê°œì›”")
        
        days = months * 30
        df = self.collect_daily_news(days)
        
        if df.empty:
            return {}
        
        # ê°ì • ë¶„ì„
        positive_keywords = SENTIMENT_CONFIG["positive_keywords"]
        negative_keywords = SENTIMENT_CONFIG["negative_keywords"]
        
        sentiment_analysis = []
        
        for _, row in df.iterrows():
            title_content = f"{row['title']} {row['content']}"
            
            positive_count = sum(1 for keyword in positive_keywords if keyword in title_content)
            negative_count = sum(1 for keyword in negative_keywords if keyword in title_content)
            
            if positive_count > negative_count:
                sentiment = "positive"
            elif negative_count > positive_count:
                sentiment = "negative"
            else:
                sentiment = "neutral"
            
            sentiment_analysis.append({
                'title': row['title'],
                'category': row['category'],
                'sentiment': sentiment,
                'positive_score': positive_count,
                'negative_score': negative_count,
                'date': row['date']
            })
        
        sentiment_df = pd.DataFrame(sentiment_analysis)
        
        # ê°ì •ë³„ í†µê³„
        sentiment_stats = sentiment_df.groupby(['sentiment', 'category']).size().unstack(fill_value=0)
        
        # CSV ì €ì¥
        filename = f"swing_sentiment_analysis_{datetime.now().strftime('%Y%m%d')}.csv"
        sentiment_df.to_csv(filename, index=False, encoding="utf-8-sig")
        
        logger.info(f"ê°ì • ë¶„ì„ ì™„ë£Œ: {filename}")
        logger.info(f"ê°ì •ë³„ í†µê³„:\n{sentiment_stats}")
        
        return {
            'sentiment_df': sentiment_df,
            'sentiment_stats': sentiment_stats,
            'total_news': len(df)
        }
    
    def get_swing_recommendations(self) -> Dict[str, Any]:
        """ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ì¶”ì²œ ë‰´ìŠ¤"""
        logger.info("ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ì¶”ì²œ ë‰´ìŠ¤ ë¶„ì„ ì‹œì‘")
        
        # 1. ì¼ê°„ ë‰´ìŠ¤ (ìµœê·¼ 5ì¼)
        daily_news = self.collect_daily_news(5)
        
        # 2. íŠ¸ë¦¬ê±° ë‰´ìŠ¤ (ìµœê·¼ 7ì¼)
        trigger_news = self.collect_trigger_news(7)
        
        # 3. ê°ì • ë¶„ì„ (ìµœê·¼ 1ê°œì›”)
        sentiment_analysis = self.analyze_news_patterns(1)
        
        recommendations = {
            'daily_news_count': len(daily_news),
            'trigger_news_count': len(trigger_news),
            'top_triggers': trigger_news.head(10).to_dict('records') if not trigger_news.empty else [],
            'sentiment_summary': sentiment_analysis.get('sentiment_stats', {}),
            'recommendation': self._generate_recommendation(daily_news, trigger_news, sentiment_analysis)
        }
        
        return recommendations
    
    def _generate_recommendation(self, daily_news: pd.DataFrame, 
                               trigger_news: pd.DataFrame, 
                               sentiment_analysis: Dict) -> str:
        """ì¶”ì²œ ë©”ì‹œì§€ ìƒì„±"""
        if daily_news.empty:
            return "ìˆ˜ì§‘ëœ ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        # íŠ¸ë¦¬ê±° ë‰´ìŠ¤ê°€ ë§ìœ¼ë©´ í™œë°œí•œ ì‹œì¥
        if len(trigger_news) > 20:
            market_condition = "ë§¤ìš° í™œë°œ"
        elif len(trigger_news) > 10:
            market_condition = "í™œë°œ"
        else:
            market_condition = "ë³´í†µ"
        
        # ê°ì • ë¶„ì„ ê²°ê³¼
        sentiment_stats = sentiment_analysis.get('sentiment_stats', {})
        if hasattr(sentiment_stats, 'sum') and 'positive' in sentiment_stats.index:
            positive_ratio = sentiment_stats.loc['positive'].sum() / sentiment_stats.sum().sum()
            if positive_ratio > 0.6:
                sentiment = "ê¸ì •ì "
            elif positive_ratio < 0.4:
                sentiment = "ë¶€ì •ì "
            else:
                sentiment = "ì¤‘ë¦½ì "
        else:
            sentiment = "ë¶„ì„ ë¶ˆê°€"
        
        recommendation = f"""
ğŸ“Š ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ì‹œì¥ ë¶„ì„ ê²°ê³¼

ğŸ“ˆ ì‹œì¥ í™œì„±ë„: {market_condition}
ğŸ’­ ì‹œì¥ ê°ì •: {sentiment}
ğŸ“° ì¼ê°„ ë‰´ìŠ¤: {len(daily_news)}ê°œ
ğŸ¯ íŠ¸ë¦¬ê±° ë‰´ìŠ¤: {len(trigger_news)}ê°œ

ğŸ’¡ ì¶”ì²œ:
- {market_condition}í•œ ì‹œì¥ì—ì„œëŠ” ë‹¨ê¸° ìŠ¤ìœ™(2-3ì¼) ì „ëµ ê³ ë ¤
- {sentiment} ê°ì •ì—ì„œëŠ” ì‹ ì¤‘í•œ ì§„ì…ê³¼ ë¹ ë¥¸ ì†ì ˆ ê¶Œì¥
- íŠ¸ë¦¬ê±° ë‰´ìŠ¤ê°€ ë§ì„ ë•ŒëŠ” ì´ìŠˆ ê¸°ë°˜ ë§¤ë§¤ ê¸°íšŒ ì¦ê°€
        """
        
        return recommendation
    
    def close(self):
        """í¬ë¡¤ëŸ¬ ì¢…ë£Œ"""
        self.crawler.close()

# ì‚¬ìš© ì˜ˆì‹œ
def main():
    collector = SwingNewsCollector()
    
    try:
        # ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ì¶”ì²œ ë¶„ì„
        recommendations = collector.get_swing_recommendations()
        
        print("=== ìŠ¤ìœ™ íŠ¸ë ˆì´ë”© ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼ ===")
        print(f"ì¼ê°„ ë‰´ìŠ¤: {recommendations['daily_news_count']}ê°œ")
        print(f"íŠ¸ë¦¬ê±° ë‰´ìŠ¤: {recommendations['trigger_news_count']}ê°œ")
        print("\n" + recommendations['recommendation'])
        
        # ìƒìœ„ íŠ¸ë¦¬ê±° ë‰´ìŠ¤ ì¶œë ¥
        if recommendations['top_triggers']:
            print("\n=== ìƒìœ„ íŠ¸ë¦¬ê±° ë‰´ìŠ¤ ===")
            for i, news in enumerate(recommendations['top_triggers'][:5], 1):
                print(f"{i}. {news['title']}")
                print(f"   í‚¤ì›Œë“œ: {news.get('matched_keywords', 'N/A')}")
                print()
        
    finally:
        collector.close()

if __name__ == "__main__":
    main() 